state:int	title:string	subtitle:string	opacity:float	prevenabled:int	nextenabled:int	resetenabled:int
0			0	0	1	0
1	Motivation	Suppose we have a single server and a single client who wishes to send a request to the server. Click on the client to send its request.	1	1	1	1
2	Motivation	What happens if the server crashes or becomes unresponsive? This service has a single point of failure; when the server fails, the service can no longer process client requests. How can we make our service withstand server failures ?	1	1	1	0
3	Motivation	To add a form of fault-tolerance, we replicate the service state across multiple servers. The client sends a request to all the replica servers, who in turn all update their state. Click on the client to broadcast its request. 	1	1	1	1
4	Motivation	Even if one server crashes, its state is replicated across several other servers. As long as one replica stays alive, the client request can be processed.	1	1	1	1
5	Motivation	What happens if there are multiple clients, all simulatenously sending requests to the servers? The replicas must all process the same client request, or they would become desynchronized. Click on either client to broadcast its request. Try to desynchronize the replicas by clicking on  the two clients in rapid succession (it may take a few tries)!	1	1	1	1
6	Motivation	We could have a single primary server that chooses which client request to process an dbroadcasts it to the replicas. Click on either client to send its request. Once the primary has chosen a request, click on it to broadcast it to the replicas.	1	1	1	1
7	Motivation	Again, what happens if the primary server crashes? Just like before, our service has a single point of failure; one machine failing means we can no longer serve clients.	1	1	1	0
8	Motivation	To remove any single point of failure and still have fault-tolerance, we can make the replicas decide amongst themselves which client request to process. This problem is called distributed consensus, since the replicas make a collective decision without a centralized coordinator.	1	1	1	0
9	Paxos	Paxos is the typical algorithm for performing distributed consensus. In the algorithm, servers vote on client requests, and process one request once a majority has voted on it.	1	1	1	0
10	Paxos Clusters	In the Paxos algorithm, a server can take on one of three roles in the consensus process.	1	1	1	0
11	Paxos Clusters	The first role is the <span class='proposer'>proposer</span>, who receives client messages and attempts to get them voted on by proposing them.	1	1	1	0
12	Paxos Clusters	The second role is the <span class='acceptor'>acceptor</span>, who receives proposals for client requests and votes on them.	1	1	1	0
13	Paxos Clusters	The third role is the <span class='learner'>learner</span>, who learns when a proposed request has been elected by the cluster. <span class='learner'>Learners</span> process elected requests, acting as replicas for the server state.	1	1	1	0
14	Paxos Walkthrough	The algorithm starts with the client sending its request to all <span class='proposer'>proposers</span>. <span class='proposer'>Proposers</span> store the request they're advocating for (null initially). <span class='proposer'>Proposers</span> enumerate their request using a serial number unique among the <span class='proposer'>proposers</span> (1 initially). <span class='proposer'>Proposers</span> record how many <span class='acceptor'>acceptors</span> have committed to their serial number, any how many have committed to their request (0/1, 0/1).	1	1	1	1
15	Paxos Prepare Phase	<span class='proposer'>Proposers</span> ask all <span class='acceptor'>acceptors</span> to "prepare" their client request by committing to the request's serial number. <span class='acceptor'>Acceptors</span> store the highest serial number they've seen (-1 initially), and refuse to commit to any lower serial numbers. <span class='acceptor'>Acceptors</span> store the client request associated with the highest serial number they've seen (null initially).	1	1	1	1
16	Paxos Prepare Phase	If <span class='acceptor'>acceptors</span> see a higher serial number than they've seen before, they commit to it, "preparing" for a corresponding client request from a <span class='proposer'>proposer</span>. Crucially, if an acceptor previously voted on a request (not null), they include it in their response, and the proposer must advocate for it in favor of their previous client request. This ensures that once a request is elected by a majority of acceptors, a new one won't replace it. <span class='proposer'>Proposers</span> record how many <span class='acceptor'>acceptors</span> have "prepared" for their serial number (0/1 initially). <span class='proposer'>Proposers</span> stop accepting "prepare" responses once a majority of <span class='acceptor'>acceptors</span> have committed to their serial number (1 in this case).	1	1	1	1
17	Paxos Vote Phase	Once <span class='proposer'>proposers</span> have a majority of "prepare" responses, they ask all <span class='acceptor'>acceptors</span> to vote for their client request. <span class='acceptor'>Acceptors</span> always vote for requests with a serial number at least as high as they highest they've seen. <span class='acceptor'>Acceptors</span> record the client command they voted for (and increase their serial number if they see a higher one at this stage).	1	1	1	1
18	Paxos Vote Phase	If <span class='acceptor'>acceptors</span> see a serial number at least as high as the highest they know about, they vote for the corresponding client request. <span class='proposer'>Proposers</span> record how many <span class='acceptor'>acceptors</span> have voted for their client request (0/1 initially). <span class='proposer'>Proposers</span> stop accepting votes once a majority of <span class='acceptor'>acceptors</span> have voted for their client command (1 in this case).	1	1	1	1
19	Paxos Learn Phase	Once <span class='proposer'>proposers</span> have a majority of votes for their client request, they notify all <span class='learner'>learners</span> about the request. <span class='learner'>Learners</span> store and execute the elected client request (null initially). Paxos ensures that only one client request will ever be voted on by a majority, since any two majorities overlap; If a majority of <span class='acceptor'>acceptors</span> has voted on a request, any <span class='proposer'>proposer</span> who receives a majority of <span class='acceptor'>acceptor</span> responses will see the request and start advocating for it in favor of their current client request.	1	1	1	1
20	Paxos Learn Phase	Once <span class='learner'>learners</span> learn of a client request that a majority of <span class='acceptor'>acceptors</span> has voted on, they are free to service the request and respond to the client, if necessary. Paxos ensures that the elected request will not change, so all <span class='learner'>learners</span> will eventually learn of the same client request and remain in sync. The <span class='learner'>learners</span> are the replicas of a Paxos cluster, so the election process yields a replicated service that can tolerate a significant number of faults. Since Paxos only needs a majority of <span class='acceptor'>acceptors</span> for progress to be made, a Paxos cluster can tolerate up to a minority (half) of <span class='acceptor'>acceptors</span> failing.	1	1	1	1
21	Paxos Demo	caption for state 21	1	1	0	1
